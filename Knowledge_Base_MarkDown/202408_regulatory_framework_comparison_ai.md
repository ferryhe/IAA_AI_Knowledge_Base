# 202408 regulatory-framework-comparison-ai

## Page 1
# Comparison of Regulatory Framework for Non-Discriminatory AI Usage in Insurance

August | 2024
![Page 1 Image 1](202408_regulatory-framework-comparison-ai_assets/202408_regulatory-framework-comparison-ai_p01_img1.jpg)
![Page 1 Image 2](202408_regulatory-framework-comparison-ai_assets/202408_regulatory-framework-comparison-ai_p01_img2.jpg)
![Page 1 Image 3](202408_regulatory-framework-comparison-ai_assets/202408_regulatory-framework-comparison-ai_p01_img3.jpg)

## Page 2
# Comparison of Regulatory Framework for Non-Discriminatory AI Usage in Insurance 

AUTHORS David Schraub, FSA, CERA, MAAA, AQ

Jing Lang, FSA, FCIA, MAAA, FLMI

Zhibin Zhang, FSA, FCIA

Mark A. Sayre, FSA, CERA, JD, CIPP/US|E

SPONSOR Actuarial Innovation and Technology Strategic Research Program Steering Committee

## Give us your feedback! Take a short survey on this report.

## Caveat and Disclaimer

The opinions expressed and conclusions reached by the authors are their own and do not represent any official position or opinion of the Society of Actuaries Research Institute, the Society of Actuaries or its members. The Society of Actuaries Research Institute makes no representation or warranty to the accuracy of the information.

Copyright © 2024 by the Society of Actuaries Research Institute. All rights reserved.

## Page 3
# CONTENTS 

Executive Summary ..... 5
Section 1: United States ..... 6
1.1 Artificial Intelligence and Insurance Industry Regulation in Context. ..... 6
1.2 Regulatory Bodies Relevant for AI Regulation in the Insurance Industry. ..... 6
1.3 Current Developments ..... 6
Section 2: European Union ..... 9
2.1 Artificial Intelligence and Insurance Industry Regulation in Context. ..... 9
2.2 Regulatory Bodies Relevant for AI Regulation in the Insurance Industry. ..... 9
2.3 Current Developments ..... 10
Section 3: China ..... 12
3.1 Artificial Intelligence and Insurance Industry Regulation in Context. ..... 12
3.2 Regulatory Bodies Relevant for AI Regulation in the Insurance Industry. ..... 12
3.3 Current Developments ..... 13
Section 4: Canada ..... 15
4.1 Artificial Intelligence and Insurance Industry Regulation in Context. ..... 15
4.2 Regulatory Bodies Relevant for AI Regulation in the Insurance Industry. ..... 15
4.3 Current Developments ..... 16
Section 5: Acknowledgments ..... 17
About the Casualty Actuarial Society ..... 18
About The Society of Actuaries Research Institute ..... 19

## Page 4
# Comparison of Regulatory Framework for Non-Discriminatory AI Usage in Insurance 

The Artificial Intelligence (AI) Index 2024 Annual Report ${ }^{1}$ by Stanford University indicates that "funding for generative AI surged, nearly octupling from 2022 to reach $\$ 25.2$ billion," and "[p]eople across the globe are more cognizant of AI's potential impact - and more nervous." Responding to this greater awareness of, and concern about, AI, regulators have begun to take action in ways that aim to achieve the benefits of AI innovation, while avoiding or mitigating the risks posed by its rapid and widespread adoption.

The insurance industry is no exception. Examples of ways in which insurance regulators and the actuarial community are responding to the use of AI in insurance include the revision of the Continuing Education Requirements for the U.S. Qualification Standard ${ }^{2}$ (Bias Topic CE - New Requirement in Section 2.2.6) and the creation of the H Committee ${ }^{3}$ at the National Association of Insurance Commissioners (NAIC) in the U.S.

Actuaries should understand the ways in which the emerging regulatory environment is likely to affect their work and their professional responsibility. The first critical step in this process is awareness. Accordingly, this report aims to provide actuaries with an introduction to current regulatory trends related to the use of AI in insurance. The report focuses on four jurisdictions in particular, which are most relevant to the Society of Actuaries and other sponsoring organizations: The United States, The European Union (EU), Canada, and China.

Readers should note that this is a rapidly evolving area. This report aims to provide readers with an up-todate overview of the regulatory landscape, but the information contained here is likely to change.

[^0]
[^0]:    ${ }^{1}$ https://aindex.stanford.edu/wp-content/uploads/2024/05/HAI_AI-Index-Report-2024.pdf
    ${ }^{2}$ https://www.actuary.org/sites/default/files/2021-11/USQS_2021.pdf
    ${ }^{3}$ https://content.naic.org/cmite_h.htm

## Page 5
# Executive Summary

The need for AI regulation is understood by the authorities in all four jurisdictions. Although commonalities exist among the areas, likely driven by the cross-border nature of the technologies involved, the differences in general, regulatory approach and principles by jurisdiction, have resulted in critical dissimilarities. Common themes include a focus on transparency, traceability, governance, risk management, testing and documentation, and accountability. Differences appear to be primarily the result of the varied regulatory philosophies (e.g., the federalist model of state-led regulation in the U.S. vs. the centralized model in China), legislative approach (industry-specific vs. cross-industry regulation), and regulatory approach (e.g., a focus on protection of rights vs. a focus on fostering technological innovation).

Table 1 SUMMARY TABLE ${ }^{4}$

|  Topic | United States | ED | China | Canada  |
| --- | --- | --- | --- | --- |
|  Insurance regulation
approach | Decentralized | Centralized | Centralized | Mix  |
|  AI regulation approach | Mostly industry
specific | Cross industry | Cross industry | Mix  |
|  Regulatory authority | NAIC H committee
Individual states like
Colorado, CT, NY | EIOPA | NFRA | OSFI
Individual provinces  |
|  Piece of regulation | NAIC AI Bulletin
SB21-169
24-205 | DORA-GDPR
EU IA act | MOST | AIDA  |

## Give us your feedback!

Take a short survey on this report.

## Page 6
# Section 1: United States 

### 1.1 ARTIFICIAL INTELLIGENCE AND INSURANCE INDUSTRY REGULATION IN CONTEXT

In the United States, the insurance industry is unique in that it is predominantly regulated by the states rather than the federal government. The leading role of the states as the primary insurance market regulators was solidified by the McCarran-Ferguson Act of 1945. States are responsible for both the market conduct and solvency aspects of industry oversight. Perhaps the most visible example of state dominance in insurance regulation is the fact that insured products, including any associated marketing materials and policy forms and, in many instances, the premiums to be charged, must be filed with and approved by state regulators.

Artificial Intelligence is an emerging technology that is rapidly being adopted in the U.S. across all industries. The industry-agnostic nature of AI technology means that general regulatory principles, such as the emphasis on competitive and free markets that foster innovation, are the predominant approach to current regulation. However, tensions are rapidly emerging, both among the states and between the states and the federal government, as states begin to take the lead on data privacy and AI regulation in the absence of comprehensive federal legislation.

### 1.2 REGULATORY BODIES RELEVANT FOR AI REGULATION IN THE INSURANCE INDUSTRY

Each state has established a particular agency, often called the department of insurance, with an appointed or elected director, which enforces the laws and regulations of the respective state. The role of the federal government is limited, especially with respect to individual insurance such as life, annuities, and disability.

To prevent undue divergence of the insurance market between the 50 states and related territories, the National Association of Insurance Commissioner (NAIC) has established an accreditation process to ensure that each state meets a baseline standard of regulation and simplify the regulatory burden on multi-state insurance companies. The NAIC also issues guidance on particular topics to all states to promote uniformity as states update their regulatory and supervisory frameworks.

Other relevant quasi-governmental bodies include the National Council of Insurance Legislators (NCOIL), which helps craft uniform legislation that can be subsequently introduced through each state's respective legislative process, and the Federal Insurance Office (FIO), which is part of the U.S. Department of Treasury and has a combination of domestic duties, such as monitoring the industry in general and over specific federal programs (e.g., the Terrorism Risk Insurance Program established by Congress after the September 11th attacks), and international duties.

### 1.3 CURRENT DEVELOPMENTS

In this developing area where new changes take place on a weekly basis, many stakeholders are moving independently, but in the same general direction. At the federal level, the executive branch has issued a Blueprint for an AI Bill of Rights ${ }^{5}$ through an executive order ${ }^{6}$ on October 30, 2023, and other actions.

[^0]
[^0]:    ${ }^{5}$ https://www.whitehouse.gov/ostp/ai-bill-of-rights/
    ${ }^{6}$ https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/\#:":text=With\%20this\%20Executive\%20Order\%2C\%20the,information\%20with\%20the\%20U.S.\%20government

## Page 7
Further guidance is likely to emerge over the coming year. Importantly, current guidance indicates that labeling may be required for AI-generated content<sup>7</sup>.

Regarding the insurance industry, states leveraged the adopted NAIC AI Bulletin<sup>8</sup> in December 2023 to update their individual frameworks. Some states are going even further and issuing specific guidance.

Among the states, Colorado has been the most active with respect to the use of AI, both in insurance and generally. In mid-2021, Colorado passed SB21-169 - Protecting Consumers from Unfair Discrimination in Insurance Practices<sup>9</sup>, which "protects Colorado consumers from insurance practices that result in unfair discrimination on the basis of race, color, national or ethnic origin, religion, sex, sexual orientation, disability, gender identity, or gender expression." The legislation holds insurers accountable for testing their big data systems - including external consumer data and information sources, algorithms, and predictive models - to ensure they do not unfairly discriminate against consumers on the basis of a protected class. SB21-169 requires insurers to "take corrective action to address any consumer harms that are discovered," per the Colorado Department of Regulatory Agencies (DORA). Regulation 10-1-1 for the life insurance industry<sup>10</sup> was effective as of November 14, 2023, and the process is underway for private auto and health insurance regulation. In these documents, there is no Pass / Fail criteria, but a risk management framework is imposed that should document external consumer data and information sources: value and objective, governance structure, senior management responsibilities, ethic committee make-up, ethic committee policies and procedures, consumer complaint-handling process, rubric for risk assessment of the model, data inventory and version control, inventory change management, testing conducted, ongoing monitoring, third party vendor selection process, and comprehensive annual review process. In essence, "Please do the right thing, please tell us what you do." It is worth noting that draft versions of the regulation include a bright line quantitative testing requirement with threshold and required explanation if the test fails.

The state of Colorado also recently passed a general, industry-agnostic law, known as the AI Act, which requires developers of high-risk AI systems to use reasonable care to avoid algorithmic discrimination. The bill includes a "safe harbor provision," under which a developer who follows the specified provisions in the bill is entitled to a rebuttable presumption that the reasonable care standard has been satisfied. The Act applies to all industries, with insurance, financial or lending services, and health care services specifically listed. The safe harbor provision lists the same risk management framework components as Regulation 10-1-1 discussed above.

Beyond Colorado, New York has also been particularly active. The New York Department of Financial Services issued a Circular Letter<sup>11</sup> on July 11, 2024, with similar components to those found in Colorado Regulation 10-1-1. The Circular Letter is more specific than the Colorado regulation but stops short of being fully prescriptive. For example, in the section on Quantitative Assessment, the Letter indicates that "[i]nsurers are *encouraged* to use multiple statistical metrics in evaluating data and model outputs to ensure a comprehensive understanding and assessment" (emphasis added). The Circular Letter provides

<sup>7</sup> https://eshoo.house.gov/sites/evo-subsites/eshoo.house.gov/files/evo-media-document/AI%20watermarking.pdf

<sup>8</sup> Contextualize the legislative authority, define terms, set regulatory guidance and expectations (governance, risk management control, internal audit role), and oversight/examination (documentation). Third party AI systems and data have specific sections. For more, https://content.naic.org/article/naic-members-approve-model-bulletin-use-ai-insurers

<sup>9</sup> https://doi.colorado.gov/for-consumers/sb21-169-protecting-consumers-from-unfair-discrimination-in-insurance-practices

<sup>10</sup> https://drive.google.com/file/d/1dIPKJCDo76IHfJZDopQEhTDCmKbuYnNU/view

<sup>11</sup> https://www.dfs.ny.gov/industry-guidance/circular-letters/cI2024-07

## Page 8
examples of such metrics, including Adverse Impact Ratio, Denials Odds Ratio, Marginal Effects, and Standardized Mean Differences.

Other states have enacted principle-based requirements that are closer to the NAIC AI Bulletin. Note that some have slightly modified the scope of protected classes.

## Page 9
# Section 2: European Union 

### 2.1 ARTIFICIAL INTELLIGENCE AND INSURANCE INDUSTRY REGULATION IN CONTEXT

In Europe, the insurance industry is mostly regulated via legislation at the European level and generally takes one of two forms: directives, which are later incorporated into member state law through separate legislative action by each member state; and regulations, which are automatically binding for all member states.

The technology industry is also regulated at the EU level, with recent pieces of legislation including General Data Protection and Regulation (GDPR) ${ }^{12}$ and Digital Operational Resilience Act (DORA) ${ }^{13}$. Additionally, Open Insurance ${ }^{14}$ is an initiative that would clarify the framework around data exchange across the countries within the EU.

### 2.2 REGULATORY BODIES RELEVANT FOR AI REGULATION IN THE INSURANCE INDUSTRY

Legislation in Europe is created through three-party discussions (trilogue) among the European Commission (executive branch), the European Parliament (composed of elected individuals), and the Council of the European Union (Head of state or relevant ministry). Technical agencies within the European Union provide technical recommendations on proposed legislation. The main body relevant to the insurance industry is the European Insurance and Occupational Pensions Authority (EIOPA) ${ }^{15}$, which serves as "an independent advisory body to the European Commission, the European Parliament and the Council of the European Union." EIOPA is one of the EU agencies tasked with "carrying out specific legal, technical or scientific tasks and giving evidence-based advice to help shape informed policies and laws at the EU and national level." Numerous similar bodies exist for industries related to insurance, such as the European Banking Authority (EBA), European Securities and Markets Authority (ESMA), and European Institute of Innovation \& Technology (EIT), with some overlapping authority. These agencies differ in the ways in which they engage industry stakeholders (business, education, research).

The transcription of the EU guidance into country laws, where necessary, should be performed in a timely fashion ${ }^{16}$, and country specific regulators perform primary oversight, although some oversight may also be performed at the European Union level (e.g., the European Data Protection Board, which has some oversight responsibility under the GDPR). For example, France's Autorité de Contrôle Prudentiel et de Résolution (ACPR) supervises both the banking and insurance sectors and is backed by France's central bank, the Banque de France. It is responsible for both financial stability and consumer protection. Other European countries have systems that are similar in essence. However, strong differences exist between European countries as a result of differing policyholder expectations, tax systems, and culture. The enforcement practice of a given regulation also varies among countries.

[^0]
[^0]:    12 This 2018 European law governs the way companies can use, process, and store personal information. It requires active explicit specific consent for a given usage, and has requirements around fair and transparent use, purpose limitation, data minimization, accuracy, storage limitation, and integrity and confidentiality. https://gdor-info.eu/
    13 This 2023 European law focuses on IT security of financial firms, with cybersecurity in mind. The five pillars are governance, risk management, incidence reporting, resilience testing, and information/intelligence sharing. https://www.eiopa.europa.eu/digital-operational-resilience-act-dora en
    14 https://www.eiopa.europa.eu/browse/digitalisation-and-financial-innovation/open-insurance en
    15 https://www.eiopa.europa.eu/index en
    16 The precise timeline of this mandate depends on each regulation, decision or directive with specific processes in each case. https://commission.europa.eu/law/application-eu-law/implementing-eu-law en

## Page 10
# 2.3 CURRENT DEVELOPMENTS 

The AI Act was recently passed on December 9, 2023. Ursula von der Leyen, President of the European Commission, is quoted in the press release announcing passage of the law:
"The EU's AI Act is the first-ever comprehensive legal framework on Artificial Intelligence worldwide. [..]The AI Act transposes European values to a new era. By focusing regulation on identifiable risks, today's agreement will foster responsible innovation in Europe. By guaranteeing the safety and fundamental rights of people and businesses, it will support the development, deployment and take-up of trustworthy AI in the EU. Our AI Act will make a substantial contribution to the development of global rules and principles for human-centric AI."

The final document was endorsed by the member states to finalize the AI Act. The English version of the act is 458 pages long ${ }^{17}$, but the EU provides a high-level summary of the AI Act on the website dedicated to discussion of the law ${ }^{18}$.

Table 2
REQUIREMENTS BASED ON RISK TO THE POPULATION

| Level | Requirements | General Example | Insurance Use Case |
| :--: | :--: | :--: | :--: |
| Minimal risk | No regulation | Recommendation engine | Price comparison |
| Limited risk | Transparency requirements | Chatbot, emotion recognition | Customer support |
| High risk | Strict requirements (risk-mitigation systems, high quality of data sets, logging of activity, detailed documentation, clear user information, human oversight, and a high level of robustness, accuracy, and cybersecurity) | Critical infrastructures; medical devices; access to educational institutions; recruitment tool; law enforcement, border control, specifically including biometric identification, categorization, and emotion recognition systems | Some activity may fall under high risk level: insurance pricing and UW; insurance marketing; insurance risk management |
| Unacceptable risk | Banned | Manipulate human behavior, social scoring | No insurance use case |

Some use of AI in the insurance industry is automatically considered high risk, especially the underwriting and pricing process, as specifically referenced in Article 6(2).5.c: "AI systems intended to be used for risk assessment and pricing in relation to natural persons in the case of life and health insurance." Other uses of AI in the insurance industry may fall within the high risk or the limited risk category; such uses would need to be evaluated according to the definitions and examples provided in the Act.

Commercial insurance will be impacted by the classification of the insured risk (e.g., cyber insurance contract covering the IT needs of a nuclear power plant or an E\&O coverage for the C-suite of an airport security firm using facial recognition to prohibit the entrance of unauthorized individuals). Other parts of the insurance industry are currently reviewing the precise impact and potential as-yet-unknown interactions among this new regulation, GDPR, and DORA. The January 2023 EIOPA Discussion paper on Open Insurance shows efforts to balance innovation and regulation.

[^0]
[^0]:    ${ }^{17}$ https://www.europarl.europa.eu/doceo/document/TA-9-2024-0138-FNL-COR01_EN.pdf
    ${ }^{18}$ https://artificialintelligenceact.eu/high-level-summary/

## Page 11
In January 2024, the EU launched an AI innovation package ${ }^{19}$ to support small and medium-sized companies in developing trustworthy AI. It includes the GenAI4EU initiative to help develop use case and emerging applications; the EU IA office ${ }^{20}$, officially launched in June 2024, which is aimed at developing and implementing trustworthy AI (including by providing support to member states to transcribe the framework into local law); and some financial support for generative AI projects and other public / private partnership programs.

## Page 12
# Section 3: China 

### 3.1 ARTIFICIAL INTELLIGENCE AND INSURANCE INDUSTRY REGULATION IN CONTEXT

Insurance regulation in China is overseen by the National Financial Regulatory Administration (NFRA). Such regulation includes stringent licensing requirements for insurers, supervision of financial solvency and risk management, and enforcement of market conduct standards. NFRA also mandates regular reporting and audits, sets prudential rules on capital adequacy and reserves, and monitors compliance with consumer protection laws. Use of AI in the insurance sector also falls under the scope of NFRA's authority and NFRA is tasked with ensuring that insurance-specific use of AI aligns with national standards and ethical guidelines. This includes scrutiny of AI applications in risk assessment, underwriting, and customer service to prevent issues like bias and violation of data protection laws.

In China, there is as of yet no specific AI regulation exclusively for the insurance industry. Instead, AI regulation in China is governed by a comprehensive and overarching framework that applies to various industries, including insurance. The main regulatory framework for AI in China is the "Interim Measures for the Management of Generative Artificial Intelligence Services," which was established in 2023. For the insurance industry specifically, these general AI regulations apply alongside existing insurance regulations.

### 3.2 REGULATORY BODIES RELEVANT FOR AI REGULATION IN THE INSURANCE INDUSTRY

Government oversight of AI in China involves multiple governmental agencies and regulatory bodies, reflecting the country's multifaceted approach to managing and promoting AI development.

Principal among these is the Ministry of Science and Technology (MOST), but several other organizations also play significant roles, including:

- Cyberspace Administration of China (CAC), which plays a crucial role in relation to data privacy, cybersecurity, and the ethical use of AI;
- National Development and Reform Commission (NDRC), which is involved in the strategic planning and economic aspects of AI development;
- Ministry of Industry and Information Technology (MIIT), which regulates the industrial and information technology sectors and plays a significant role in the standardization, industrial policymaking, and promotion of AI technologies across various industries;
- China Academy of Information and Communications Technology (CAICT), which is a research institution under the MIIT that provides technical support, policy research, and standard development for AI;
- China Artificial Intelligence Industry Alliance (AIIA), which, supported by the MIIT, brings together enterprise, research institutions, and other stakeholders to promote AI industry standards, innovation, and collaboration; and
- Standardization Administration of China (SAC), which is responsible for setting technical standards, including those for AI technologies.

The NFRA is a financial regulatory body under the State Council of the People's Republic of China. It was established on March 10, 2023, to replace the China Banking and Insurance Regulatory Commission (CBIRC). The NFRA has a slightly broader scope than its predecessor and plays a comprehensive and pivotal role in regulating and supervising the insurance industry across the country. It is responsible for developing and implementing regulatory policies and frameworks for the insurance industry, including drafting regulations, guidelines, and standards that govern the operations of insurance companies, brokers, and agents. At a local level, the provincial insurance authorities adapt and implement national insurance

## Page 13
policies to suit local conditions. This may involve tailoring regulations to address specific regional issues or support local economic development initiatives.

# 3.3 CURRENT DEVELOPMENTS 

China has established a comprehensive framework for regulating algorithms and AI through three main regulations: the 2021 regulation on recommendation algorithms; the 2022 rules for synthetically generated content; and the 2023 draft and interim rules on generative AI. Central to these regulations is the control of information, but they also encompass significant requirements for disclosure, model auditing, and technical performance standards. These regulations focus on algorithm recommendation, synthetically generated media, and generative AI systems such as OpenAI's ChatGPT.

The 2021 Provisions on the Management of Algorithmic Recommendations ${ }^{21}$ were enacted by the Cyberspace Administration of China (CAC) to address challenges in online algorithmic recommendations. These provisions aim to promote healthy development, protect user rights, and maintain national security and social stability. The regulations cover a wide range of services, including social media and e-commerce and mandating transparency about algorithm operations. Service providers must publicly disclose the principles, purpose, and functioning of their algorithms, including data collection and usage. Users have the right to disable algorithmic recommendations and request explanations for significant algorithmic decisions. The regulation emphasizes content control to prevent the promotion of illegal or harmful content, requiring robust monitoring mechanisms. An algorithm registry is established to document compliance, ensuring algorithms meet regulatory standards. Ethical considerations are crucial, prohibiting discrimination based on race, nationality, or gender. Finally, providers must implement security measures to protect algorithms from misuse and conduct regular risk assessments. The CAC enforces compliance through inspections, audits, and penalties for violations.

The 2022 Provisions on the Administration of Deep Synthesis Internet Information Services ${ }^{22}$ address the use and impact of deep synthesis technologies, including the generation and modification of images, videos, audio, and text. Effective from January 10, 2023, these regulations aim to promote healthy development, protect individual rights, and safeguard national security. Providers must register their technologies with the CAC, disclosing their functions, intended use, and compliance measures. They are required to label synthetic content clearly to inform users about its AI-generated nature. Strict responsibilities are imposed to prevent the dissemination of illegal or harmful content, with robust monitoring mechanisms. Users have the right to manage their data usage and report misuse. Providers must ensure data security, preventing breaches and unauthorized access while adhering to strict privacy standards. Ethical considerations are emphasized to prevent discrimination and misinformation, and providers are accountable for the societal impacts of their technologies. The CAC enforces these provisions through regular inspections, audits, and penalties for non-compliance.

The 2023 Measures for the Management of Generative Artificial Intelligence Services ${ }^{23}$ expand on previous regulations, covering generative AI technologies used to create or edit images, videos, voice, and text. Initially, deep synthesis regulations focused on internet-based services, leaving a gap for offline generative

[^0]
[^0]:    ${ }^{21}$ https://www.chinalawtranslate.com/en/algorithms/
    ${ }^{22}$ https://www.chinalawtranslate.com/en/deep-synthesis/
    ${ }^{23}$ https://www.chinalawtranslate.com/en/generative-ai-interim/

## Page 14
AI. In April 2023, draft regulations required providers to ensure the accuracy, objectivity, and diversity of training data and prevent intellectual property violations. Generative AI must not produce discriminatory or false content, addressing the issue of AI hallucinations. These requirements sparked public debate, leading to less restrictive interim measures released in July 2023. Effective from August 15, 2023, these measures balance innovation with societal and ethical considerations. Providers must disclose detailed information about AI algorithms, ensuring transparency and helping users understand AI-generated content. Users must be informed about AI usage and can opt out of AI-generated content. The regulation prohibits the generation and dissemination of illegal or harmful content, mandating robust content moderation systems. Providers must protect training and generated data, complying with stringent privacy standards. Intellectual property rights must be respected, with lawful data sources used for training. The CAC oversees enforcement through inspections, audits, and penalties for violations.

These regulations collectively aim to control information, ensure transparency, and promote the ethical use of AI technologies, while safeguarding user rights and national security.

There is a new draft regulation on generative AI that was issued by the National Information Security Standardization Technical Committee, which is open for public comments until July 22, 2024. It outlines several security measures for generative AI. This is an evolving topic.

## Page 15
# Section 4: Canada 

### 4.1 ARTIFICIAL INTELLIGENCE AND INSURANCE INDUSTRY REGULATION IN CONTEXT

The insurance industry in Canada is regulated by both federal and provincial bodies, with guidelines like the EDGE principles (Explainability, Data governance, Governance, and Ethics) ${ }^{24}$ from the Office of the Superintendent of Financial Institutions (OSFI) and Quebec's Law 25 emphasizing transparency, accountability, and ethical use of AI in insurance operations.

As of yet, there is no AI-specific regulatory framework in Canada. However, Canada has taken substantial steps to regulate AI at the federal level, in particular through two primary laws, both of which are currently under review in the House of Commons: The Artificial Intelligence and Data Act (AIDA) and the Consumer Privacy Protection Act (CPPA). Combined, these laws aim to hold users of AI technologies accountable to ensure that AI use is safe and non-discriminatory.

### 4.2 REGULATORY BODIES RELEVANT FOR AI REGULATION IN THE INSURANCE INDUSTRY

The regulatory bodies relevant for AI regulation are a mix of federal - for example, OSFI, Canadian Council of Insurance Regulation (CCIR) and Financial Consumer Agency of Canada (FCAC) - and provincial regulations which focus on market conduct and transparency.

On a federal level, AIDA, if passed, would become Canada's first comprehensive law regulating AI. The Act aims to ensure that "AI systems deployed in Canada are safe and non-discriminatory and [...] hold businesses accountable for how they develop and use [AI] technologies"25. Key requirements of AIDA include: (1) risk mitigation - the Act requires businesses to implement risk mitigation strategies tailored to the type of AI system, with more stringent requirements for higher-risk systems; (2) accountability - the Act introduces governance mechanisms to address risks related to harm and bias, ensuring that AI systems are safe and fair; and (3) transparency - the regulatory development process is open and transparent, involving consultations with stakeholders including AI industry leaders, academics, and civil society.

CPPA, on the other hand, aims to modernize the Personal Information Protection and Electronic Documents Act (PIPEDA), Canada's comprehensive data protection law. Requirements outlined in CPPA include enhanced rules for the collection, use, and disclosure of personal information and an expanded role for the Privacy Commissioner, including strengthened oversight and enforcement powers. Importantly, the CPPA also regulates the use of "automated decision systems," which the Act defines as any technology that assists or replaces the judgment of human decision-makers through the use of a rules-based system, regression analysis, predictive analytics, machine learning, deep learning, a neural network, or other techniques ${ }^{26}$.

At the Provincial level, Quebec has enacted Law 25, also known as Bill 64, which aims to modernize privacy legislation and includes specific requirements for AI tools that manage personal information. The law requires that businesses perform Privacy Impact Assessments (PIA) before deploying AI systems to identify and mitigate privacy risks. The law also increases transparency requirements around business's data and cybersecurity practices and consent mechanisms prior to collecting, using, or disclosing personal

[^0]
[^0]:    ${ }^{24}$ https://www.osfi-bsif.gc.ca/en/about-osfi/reports-publications/financial-industry-forum-artificial-intelligence-canadian-perspective-responsible-ai
    ${ }^{25}$ Artificial Intelligence and Data Act (canada.ca); The Artificial Intelligence and Data Act (AIDA) - Companion document (canada.ca)
    ${ }^{26}$ Artificial Intelligence in Financial Services: The Canadian Regulatory Landscape | Knowledge | Fasken

## Page 16
information. Finally, as with other privacy laws, the law requires businesses to notify individuals and authorities in case of data breaches that are likely to cause serious harm.

# 4.3 CURRENT DEVELOPMENTS 

The Office of the Superintendent of Financial Institutions (OSFI), in collaboration with the Global Risk Institute, recently developed the EDGE principles, which stands for Explainability, Data governance, Governance, and Ethics ${ }^{27,28}$. These principles aim to ensure that AI systems are transparent, fair, and accountable, thereby building trust in AI technologies.

At the Provincial level, Quebec's Autorité des Marchés Financiers (AMF) has issued guidelines and reports on AI use in finance ${ }^{29}$. These guidelines emphasize the need for AI governance frameworks that include human accountability, resilience, efficiency, robustness, and security. They also stress the importance of fairness, consumer autonomy, and transparency in AI systems.

The insurance industry is increasingly aware of the ethical implications of AI. Companies are adopting practices to ensure that AI models do not perpetuate biases. This includes understanding the underlying assumptions in data, selecting the appropriate tools, and implementing methodologies that mitigate bias. Continuous monitoring and adjustment of AI models are essential to ensure they align with ethical standards.

Finally, the use of third-party data and AI products is common in the insurance industry. Standards around third-party risk management and independent reviews are necessary to ensure data provenance, lineage, and quality. This helps prevent regulatory arbitrage and ensures that AI systems are fair and unbiased.

In summary, Canada's approach to governing AI in the insurance industry involves a combination of legislative measures, regulatory guidelines, and industry best practices aimed at ensuring ethical use, mitigating bias, and promoting transparency and accountability. Given the rapid pace at which AI, and Generative AI in particular, is evolving, and the inevitable delays as regulators attempt to adapt and evolve the regulatory framework accordingly, actuaries in Canada should pay close attention to the regulatory environment over the coming months and years.

## Give us your feedback! Take a short survey on this report.

[^0][^1]
[^0]:    ${ }^{27}$ Financial Industry Forum on Artificial Intelligence: A Canadian Perspective on Responsible AI (osfi-bsif.gc.ca)
    ${ }^{28}$ AI in the financial sector | AMF (lautorite.qc.ca)
    ${ }^{29}$ Financial Industry Forum on Artificial Intelligence: A Canadian Perspective on Responsible AI - Office of the Superintendent of Financial Institutions (osfi-bsif.gc.ca)

[^1]:    ${ }^{27}$ Financial Industry Forum on Artificial Intelligence: A Canadian Perspective on Responsible AI (osfi-bsif.gc.ca)
    ${ }^{28}$ AI in the financial sector | AMF (lautorite.qc.ca)
    ${ }^{29}$ Financial Industry Forum on Artificial Intelligence: A Canadian Perspective on Responsible AI - Office of the Superintendent of Financial Institutions (osfi-bsif.gc.ca)

## Page 17
# Section 5: Acknowledgments 

The researchers' deepest gratitude goes to those without whose efforts this project could not have come to fruition: the Project Oversight Group for their diligent work overseeing, reviewing and editing this report for accuracy and relevance.

Project Oversight Group members:

Mujtaba Ali Shaikh, MBA

Arthur Charpentier, PhD

Victor Chen, FSA, FCIA, CERA

Steve Cheung, FSA

Ron Harasym, FSA, FCIA, MAAA, CERA

Dave Ingram, FSA, MAAA, CERA

Petar Jevtic, PhD

Diana Rangelova, MAAA, FCAS

At the Society of Actuaries Research Institute:

Joe Alaimo, ASA, ACIA, Independent Consultant

Korrel Crawford, Senior Research Administrator

Dale Hall, FSA, MAAA, CERA, Managing Director of Research

At the Casualty Actuarial Society:

Mallika Bender, FCAS, MAAA, Staff Actuary

## Page 18
# About the Casualty Actuarial Society 

The Casualty Actuarial Society (CAS) is a leading international organization for credentialing and professional education. Founded in 1914, the CAS is the world's only actuarial organization focused exclusively on property and casualty risks and serves over 9,100 members worldwide. CAS members are experts in property and casualty insurance, reinsurance, finance, risk management and enterprise risk management. Professionals educated by the CAS empower business and government to make wellinformed strategic, financial and operational decisions.

The purposes of the Casualty Actuarial Society are:

- To advance the body of knowledge of actuarial science applied to general insurance, including property, casualty and similar risk exposures
- To expand the application of actuarial science to enterprise risks and systemic risks
- To establish and maintain standards of qualification for membership
- To promote and maintain high standards of conduct and competence
- To increase the awareness of actuarial science
- To contribute to the well-being of society as a whole

In principle and in practice, the CAS values and seeks diverse participation within the property/casualty actuarial profession. In support of those values, the CAS encourages an inclusive community where differences are celebrated and all have the opportunity to participate to their fullest potential in its success. The CAS commits time and resources to accomplish this objective.

Actuaries are required to adhere to the high standards of conduct, practice and qualifications of the actuarial profession, thereby supporting the actuarial profession in fulfilling its responsibility to the public.

The Casualty Actuarial Society
4350 N. Fairfax Drive, Suite 250
Arlington, VA 22203
https://www.casact.org/

## Page 19
# About The Society of Actuaries Research Institute 

Serving as the research arm of the Society of Actuaries (SOA), the SOA Research Institute provides objective, data-driven research bringing together tried and true practices and future-focused approaches to address societal challenges and your business needs. The Institute provides trusted knowledge, extensive experience and new technologies to help effectively identify, predict and manage risks.

Representing the thousands of actuaries who help conduct critical research, the SOA Research Institute provides clarity and solutions on risks and societal challenges. The Institute connects actuaries, academics, employers, the insurance industry, regulators, research partners, foundations and research institutions, sponsors and non-governmental organizations, building an effective network which provides support, knowledge and expertise regarding the management of risk to benefit the industry and the public.

Managed by experienced actuaries and research experts from a broad range of industries, the SOA Research Institute creates, funds, develops and distributes research to elevate actuaries as leaders in measuring and managing risk. These efforts include studies, essay collections, webcasts, research papers, survey reports, and original research on topics impacting society.

Harnessing its peer-reviewed research, leading-edge technologies, new data tools and innovative practices, the Institute seeks to understand the underlying causes of risk and the possible outcomes. The Institute develops objective research spanning a variety of topics with its strategic research programs: aging and retirement; actuarial innovation and technology; mortality and longevity; diversity, equity and inclusion; health care cost trends; and catastrophe and climate risk. The Institute has a large volume of topical research available, including an expanding collection of international and market-specific research, experience studies, models and timely research.

Society of Actuaries Research Institute
8770 W Bryn Mawr Ave, Suite 1000
Chicago, IL 60631
www.SOA.org